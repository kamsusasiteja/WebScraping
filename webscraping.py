# -*- coding: utf-8 -*-
"""Webscraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Rz3Q3lkcm3nQN3SQomJUSYnZQY33KxfK
"""

!pip install bs4 requests pandas html5lib

import requests

from bs4 import BeautifulSoup

import pandas as pd

url = "https://www.mohfw.gov.in/"
page = requests.get(url)

page

content = page.content

print(content)

soup = BeautifulSoup(content,"html5lib")

soup

state_section=soup.find('section',attrs={'id':"state-data"})

state_section

cases_table=state_section.find('table')

cases_table

rows=cases_table.find_all('tr')

rows[0]

# for header in rows[0]:
#   print(header)

# for header in rows[1]:
#   print(header)

# for header in rows[0].find_all('th'):
#   print(header)

# for header in rows[0].find_all('th'):
#   print(header.text)

headers=[header.text for header in rows[0].find_all('th')] #basic comprehension

headers

# for td in rows[1].find_all('td'):
#   print(td.text)

ap=[]
for td in rows[2].find_all('td'):#2nd row is Andhra pradesh
  ap.append(td.text)

ap

dict(zip(headers,ap))

len(rows)

elimination =[0,34,35,36,37]

def extract_row(row,header):
  data=[td.text for td in row.find_all('td')]
  return dict(zip(headers,data))

cases=[]
for i,row in enumerate(rows):
  if i not in elimination:
    cases.append(extract_row(row,headers))
  else:
    pass

cases

df=pd.DataFrame(data=cases)

df

df.to_csv('./cases.csv',index="False")

import json

with open('cases.json',"w") as f:
  f.write(json.dumps(cases,indent=2))

